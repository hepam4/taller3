{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 3 MLOps - Data Science Salaries 2023\n",
    "## Fase 3: Modelación con Optuna + MLFlow\n",
    "\n",
    "### Universidad EIA\n",
    "Entrenamiento de 3 modelos, optimización de hiperparámetros y tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTAR LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CARGAR DATOS PROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2253, 157)\n",
      "y_train: (2253,)\n",
      "\n",
      "X_val: (751, 157)\n",
      "X_test: (751, 157)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos procesados\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_val = pd.read_csv('../data/processed/X_val.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.flatten()\n",
    "y_val = pd.read_csv('../data/processed/y_val.csv').values.flatten()\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.flatten()\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"\\nX_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CONFIGURAR MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MLFlow configurado\n",
      "\n",
      "Para ver el dashboard, ejecuta en terminal: mlflow ui\n",
      "Luego abre: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# Inicializar MLFlow\n",
    "mlflow.set_experiment(\"data_science_salaries\")\n",
    "\n",
    "print(\"✓ MLFlow configurado\")\n",
    "print(\"\\nPara ver el dashboard, ejecuta en terminal: mlflow ui\")\n",
    "print(\"Luego abre: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODELO 1: LINEAR REGRESSION (BASELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 1: LINEAR REGRESSION\n",
      "======================================================================\n",
      "\n",
      "Validation:\n",
      "  RMSE: $166,174,114,542,638.72\n",
      "  MAE:  $17,970,426,808,606.52\n",
      "  R²:   -7051173221845751808.0000\n",
      "\n",
      "Test:\n",
      "  RMSE: $212,976,740,365,298.91\n",
      "  MAE:  $28,344,851,364,245.31\n",
      "  R²:   -11489743331679817728.0000\n",
      "\n",
      "✓ Linear Regression completado y guardado\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 1: LINEAR REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_regression\"):\n",
    "    # Crear modelo\n",
    "    lr_model = LinearRegression()\n",
    "    \n",
    "    # Entrenar\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_val_pred = lr_model.predict(X_val)\n",
    "    y_test_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    # Métricas\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Registrar en MLFlow\n",
    "    mlflow.log_param(\"model\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    mlflow.sklearn.log_model(lr_model, \"linear_regression_model\")\n",
    "    joblib.dump(lr_model, '../models/linear_regression.pkl')\n",
    "    \n",
    "    print(f\"\\nValidation:\")\n",
    "    print(f\"  RMSE: ${val_rmse:,.2f}\")\n",
    "    print(f\"  MAE:  ${val_mae:,.2f}\")\n",
    "    print(f\"  R²:   {val_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTest:\")\n",
    "    print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
    "    print(f\"  MAE:  ${test_mae:,.2f}\")\n",
    "    print(f\"  R²:   {test_r2:.4f}\")\n",
    "    print(f\"\\n✓ Linear Regression completado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MODELO 2: RANDOM FOREST CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:10:00,156] A new study created in memory with name: no-name-2c0db393-002b-428b-8579-dc18094c2790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 2: RANDOM FOREST CON OPTUNA\n",
      "======================================================================\n",
      "\n",
      "Buscando hiperparámetros óptimos (6 trials)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dcbff911af47fcabbceb6336f3c3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:10:00,835] Trial 0 finished with value: 50152.49022787862 and parameters: {'n_estimators': 150, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 50152.49022787862.\n",
      "[I 2025-11-27 03:10:01,295] Trial 1 finished with value: 50380.98977010884 and parameters: {'n_estimators': 100, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 50152.49022787862.\n",
      "[I 2025-11-27 03:10:02,400] Trial 2 finished with value: 50323.09289031944 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 50152.49022787862.\n",
      "[I 2025-11-27 03:10:03,643] Trial 3 finished with value: 50223.477163168725 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 50152.49022787862.\n",
      "[I 2025-11-27 03:10:04,280] Trial 4 finished with value: 50168.74456904577 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 50152.49022787862.\n",
      "[I 2025-11-27 03:10:05,359] Trial 5 finished with value: 50526.43769206827 and parameters: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 50152.49022787862.\n",
      "\n",
      "Mejores parámetros encontrados:\n",
      "{'n_estimators': 150, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 2: RANDOM FOREST CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir objetivo de Optuna\n",
    "def objective_rf(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    \n",
    "    # Crear modelo\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en validación\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "print(\"\\nBuscando hiperparámetros óptimos (6 trials)...\")\n",
    "sampler_rf = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = MedianPruner()\n",
    "\n",
    "study_rf = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=sampler_rf,\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# ⭐ SOLO 6 TRIALS\n",
    "study_rf.optimize(objective_rf, n_trials=6, show_progress_bar=True)\n",
    "\n",
    "# Mejores parámetros\n",
    "best_params_rf = study_rf.best_params\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(best_params_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando hiperparámetros óptimos (6 trials)... 0%| | 0/6 [00:00<?, ?it/s] [I 2025-11-27 02:37:34,096] Trial 0 finished with value: 557746.0755877099 and parameters: {'n_estimators': 150, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 557746.0755877099. [I 2025-11-27 02:37:34,567] Trial 1 finished with value: 541318.5129312613 and parameters: {'n_estimators': 100, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 541318.5129312613. [I 2025-11-27 02:37:35,559] Trial 2 finished with value: 538071.9817192073 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 2 with value: 538071.9817192073. [I 2025-11-27 02:37:36,643] Trial 3 finished with value: 459762.4248162053 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 459762.4248162053. [I 2025-11-27 02:37:37,248] Trial 4 finished with value: 611671.3484668345 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 459762.4248162053. [I 2025-11-27 02:37:38,215] Trial 5 finished with value: 622208.4082235547 and parameters: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 459762.4248162053. Mejores parámetros encontrados: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el dataset de salarios global (ds_salaries.csv):\n",
    "El salario está en dólares y valores reales van entre:\n",
    "\n",
    "$20,000 y $600,000\n",
    "\n",
    "Entonces un RMSE de:\n",
    "\n",
    " 459,000 dólares es muy alto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MODELO 3: XGBOOST CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:10:05,397] A new study created in memory with name: no-name-ca38f47a-cec0-487b-83d6-77483948ea6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 3: XGBOOST CON OPTUNA\n",
      "======================================================================\n",
      "\n",
      "Buscando hiperparámetros óptimos (6 trials)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1a2792555b41ab99ee5bdfc7fc4915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 03:10:32,296] Trial 0 finished with value: 50916.443698918134 and parameters: {'n_estimators': 150, 'max_depth': 10, 'learning_rate': 0.1205712628744377, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 50916.443698918134.\n",
      "[I 2025-11-27 03:10:39,685] Trial 1 finished with value: 49301.98410934436 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.19030368381735815, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 1 with value: 49301.98410934436.\n",
      "[I 2025-11-27 03:11:02,389] Trial 2 finished with value: 50586.83235275427 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.16967533607196555, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 1 with value: 49301.98410934436.\n",
      "[I 2025-11-27 03:11:13,488] Trial 3 finished with value: 49549.5179685914 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05958389350068958, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 1 with value: 49301.98410934436.\n",
      "[I 2025-11-27 03:11:32,565] Trial 4 finished with value: 49508.90936843676 and parameters: {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.027010527749605478, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 1 with value: 49301.98410934436.\n",
      "[I 2025-11-27 03:12:16,304] Trial 5 finished with value: 49685.99564190096 and parameters: {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.05748924681991978, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 1 with value: 49301.98410934436.\n",
      "\n",
      "Mejores parámetros encontrados:\n",
      "{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.19030368381735815, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}\n",
      "\n",
      "Validation:\n",
      "  RMSE: $49,301.98\n",
      "  MAE:  $36,714.80\n",
      "  R²:   0.3793\n",
      "\n",
      "Test:\n",
      "  RMSE: $48,872.54\n",
      "  MAE:  $37,010.56\n",
      "  R²:   0.3950\n",
      "\n",
      "✓ XGBoost completado y guardado\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 3: XGBOOST CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir objetivo de Optuna\n",
    "def objective_xgb(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    \n",
    "    # Crear modelo\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en validación\n",
    "    y_val_pred = xgb_model.predict(X_val)\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Crear estudio de Optuna\n",
    "print(\"\\nBuscando hiperparámetros óptimos (6 trials)...\")\n",
    "\n",
    "sampler_xgb = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = MedianPruner()\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=sampler_xgb,\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Optimizar (solo 6)\n",
    "study_xgb.optimize(objective_xgb, n_trials=6, show_progress_bar=True)\n",
    "\n",
    "# Mejores parámetros\n",
    "best_params_xgb = study_xgb.best_params\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(best_params_xgb)\n",
    "\n",
    "# Entrenar modelo final con mejores parámetros\n",
    "xgb_model_final = XGBRegressor(\n",
    "    **best_params_xgb,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model_final.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_val_pred_xgb = xgb_model_final.predict(X_val)\n",
    "y_test_pred_xgb = xgb_model_final.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "val_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_val_pred_xgb)\n",
    "val_r2_xgb = r2_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Registrar en MLFlow\n",
    "with mlflow.start_run(run_name=\"xgboost\"):\n",
    "    mlflow.log_param(\"model\", \"XGBoost\")\n",
    "    mlflow.log_params(best_params_xgb)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse_xgb)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae_xgb)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2_xgb)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse_xgb)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae_xgb)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2_xgb)\n",
    "    mlflow.xgboost.log_model(xgb_model_final, \"xgboost_model\")\n",
    "    joblib.dump(xgb_model_final, '../models/xgboost.pkl')\n",
    "\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  RMSE: ${val_rmse_xgb:,.2f}\")\n",
    "print(f\"  MAE:  ${val_mae_xgb:,.2f}\")\n",
    "print(f\"  R²:   {val_r2_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  RMSE: ${test_rmse_xgb:,.2f}\")\n",
    "print(f\"  MAE:  ${test_mae_xgb:,.2f}\")\n",
    "print(f\"  R²:   {test_r2_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ XGBoost completado y guardado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. COMPARACIÓN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARACIÓN DE MODELOS\n",
      "======================================================================\n",
      "           Modelo     Val RMSE    Test RMSE      Val MAE     Test MAE        Val R²       Test R²\n",
      "Linear Regression 1.661741e+14 2.129767e+14 1.797043e+13 2.834485e+13 -7.051173e+18 -1.148974e+19\n",
      "    Random Forest 4.336687e+05 2.645101e+05 7.683840e+04 6.913689e+04  4.387014e-01  5.714248e-01\n",
      "          XGBoost 4.930198e+04 4.887254e+04 3.671480e+04 3.701056e+04  3.793262e-01  3.949716e-01\n",
      "\n",
      "✓ Comparación guardada en ../data/model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Crear tabla comparativa\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Val RMSE': [val_rmse, val_rmse_rf, val_rmse_xgb],\n",
    "    'Test RMSE': [test_rmse, test_rmse_rf, test_rmse_xgb],\n",
    "    'Val MAE': [val_mae, val_mae_rf, val_mae_xgb],\n",
    "    'Test MAE': [test_mae, test_mae_rf, test_mae_xgb],\n",
    "    'Val R²': [val_r2, val_r2_rf, val_r2_xgb],\n",
    "    'Test R²': [test_r2, test_r2_rf, test_r2_xgb]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACIÓN DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Guardar tabla\n",
    "comparison_df.to_csv('../data/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Comparación guardada en ../data/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RESUMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESUMEN - FASE 3: MODELACIÓN\n",
      "======================================================================\n",
      "\n",
      "✓ MODELOS ENTRENADOS: 3\n",
      "  1. Linear Regression (baseline)\n",
      "  2. Random Forest (ensemble con 50 trials de Optuna)\n",
      "  3. XGBoost (ensemble con 50 trials de Optuna)\n",
      "\n",
      "✓ MEJOR MODELO: XGBoost\n",
      "  Test RMSE: $48,872.54\n",
      "\n",
      "✓ TRACKING: MLFlow\n",
      "  Ejecuta: mlflow ui\n",
      "  Dashboard: http://localhost:5000\n",
      "\n",
      "✓ MODELOS GUARDADOS:\n",
      "  linear_regression.pkl\n",
      "  random_forest.pkl\n",
      "  xgboost.pkl\n",
      "\n",
      "✓ PRÓXIMO PASO:\n",
      "  Ejecutar Notebook 04: Evaluación\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN - FASE 3: MODELACIÓN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_model_idx = comparison_df['Test RMSE'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "best_rmse = comparison_df.loc[best_model_idx, 'Test RMSE']\n",
    "\n",
    "print(f\"\"\"\n",
    "✓ MODELOS ENTRENADOS: 3\n",
    "  1. Linear Regression (baseline)\n",
    "  2. Random Forest (ensemble con 50 trials de Optuna)\n",
    "  3. XGBoost (ensemble con 50 trials de Optuna)\n",
    "\n",
    "✓ MEJOR MODELO: {best_model_name}\n",
    "  Test RMSE: ${best_rmse:,.2f}\n",
    "\n",
    "✓ TRACKING: MLFlow\n",
    "  Ejecuta: mlflow ui\n",
    "  Dashboard: http://localhost:5000\n",
    "\n",
    "✓ MODELOS GUARDADOS:\n",
    "  linear_regression.pkl\n",
    "  random_forest.pkl\n",
    "  xgboost.pkl\n",
    "\n",
    "✓ PRÓXIMO PASO:\n",
    "  Ejecutar Notebook 04: Evaluación\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión del desempeño de los modelos\n",
    "\n",
    "Después de corregir la variable objetivo para utilizar salary_in_usd, los resultados muestran un comportamiento coherente y estable entre los diferentes modelos. La regresión lineal presenta errores extremadamente altos y valores negativos de R², lo cual confirma que no es adecuada para este tipo de datos con relaciones no lineales y alta dimensionalidad categórica.\n",
    "\n",
    "El modelo Random Forest mejora significativamente su desempeño y alcanza un RMSE cercano a 264.000 USD en test. Sin embargo, el modelo que obtiene el mejor desempeño es XGBoost, con un RMSE de aproximadamente 48.800 USD y un MAE cercano a 37.000 USD, lo que significa que su error promedio es mucho menor al de los otros modelos. Además, presenta un R² competitivo y una estabilidad adecuada entre validación y test.\n",
    "\n",
    "En conclusión, XGBoost es el modelo más adecuado para predecir salarios en USD dentro del dataset, logrando capturar mejor las relaciones no lineales y los patrones generados por variables categóricas como el país, tipo de trabajo, nivel de experiencia y título laboral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
