{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 3 MLOps - Data Science Salaries 2023\n",
    "## Fase 3: Modelación con Optuna + MLFlow\n",
    "\n",
    "### Universidad EIA\n",
    "Entrenamiento de 3 modelos, optimización de hiperparámetros y tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTAR LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CARGAR DATOS PROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2253, 157)\n",
      "y_train: (2253,)\n",
      "\n",
      "X_val: (751, 157)\n",
      "X_test: (751, 157)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos procesados\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_val = pd.read_csv('../data/processed/X_val.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.flatten()\n",
    "y_val = pd.read_csv('../data/processed/y_val.csv').values.flatten()\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.flatten()\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"\\nX_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CONFIGURAR MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/27 02:16:37 INFO mlflow.tracking.fluent: Experiment with name 'data_science_salaries' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MLFlow configurado\n",
      "\n",
      "Para ver el dashboard, ejecuta en terminal: mlflow ui\n",
      "Luego abre: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# Inicializar MLFlow\n",
    "mlflow.set_experiment(\"data_science_salaries\")\n",
    "\n",
    "print(\"✓ MLFlow configurado\")\n",
    "print(\"\\nPara ver el dashboard, ejecuta en terminal: mlflow ui\")\n",
    "print(\"Luego abre: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODELO 1: LINEAR REGRESSION (BASELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 1: LINEAR REGRESSION\n",
      "======================================================================\n",
      "\n",
      "Validation:\n",
      "  RMSE: $6,195,204,635,002,591.00\n",
      "  MAE:  $535,001,595,065,956.50\n",
      "  R²:   -114548441068187648000.0000\n",
      "\n",
      "Test:\n",
      "  RMSE: $6,546,359,475,646,164.00\n",
      "  MAE:  $643,134,598,509,542.25\n",
      "  R²:   -262507810408744419328.0000\n",
      "\n",
      "✓ Linear Regression completado y guardado\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 1: LINEAR REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_regression\"):\n",
    "    # Crear modelo\n",
    "    lr_model = LinearRegression()\n",
    "    \n",
    "    # Entrenar\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_val_pred = lr_model.predict(X_val)\n",
    "    y_test_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    # Métricas\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Registrar en MLFlow\n",
    "    mlflow.log_param(\"model\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    mlflow.sklearn.log_model(lr_model, \"linear_regression_model\")\n",
    "    joblib.dump(lr_model, '../models/linear_regression.pkl')\n",
    "    \n",
    "    print(f\"\\nValidation:\")\n",
    "    print(f\"  RMSE: ${val_rmse:,.2f}\")\n",
    "    print(f\"  MAE:  ${val_mae:,.2f}\")\n",
    "    print(f\"  R²:   {val_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTest:\")\n",
    "    print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
    "    print(f\"  MAE:  ${test_mae:,.2f}\")\n",
    "    print(f\"  R²:   {test_r2:.4f}\")\n",
    "    print(f\"\\n✓ Linear Regression completado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MODELO 2: RANDOM FOREST CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:16:41,177] A new study created in memory with name: no-name-1204d2a0-6121-4a58-8048-0f3b4e0edd0e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 2: RANDOM FOREST CON OPTUNA\n",
      "======================================================================\n",
      "\n",
      "Buscando hiperparámetros óptimos (50 trials)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c3cb7d3f664118ba978a19ae49c8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:16:41,766] Trial 0 finished with value: 557746.0755877099 and parameters: {'n_estimators': 150, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 557746.0755877099.\n",
      "[I 2025-11-27 02:16:42,324] Trial 1 finished with value: 541318.5129312613 and parameters: {'n_estimators': 100, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 541318.5129312613.\n",
      "[I 2025-11-27 02:16:43,340] Trial 2 finished with value: 538071.9817192073 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 2 with value: 538071.9817192073.\n",
      "[I 2025-11-27 02:16:44,417] Trial 3 finished with value: 459762.4248162053 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 459762.4248162053.\n",
      "[I 2025-11-27 02:16:45,028] Trial 4 finished with value: 611671.3484668345 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 459762.4248162053.\n",
      "[I 2025-11-27 02:16:46,006] Trial 5 finished with value: 622208.4082235547 and parameters: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 459762.4248162053.\n",
      "[I 2025-11-27 02:16:46,805] Trial 6 finished with value: 577457.964646882 and parameters: {'n_estimators': 200, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 459762.4248162053.\n",
      "[I 2025-11-27 02:16:47,596] Trial 7 finished with value: 455403.5993690506 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:48,046] Trial 8 finished with value: 541340.2994957735 and parameters: {'n_estimators': 100, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:48,691] Trial 9 finished with value: 558188.2332130515 and parameters: {'n_estimators': 150, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:49,449] Trial 10 finished with value: 456523.72367005056 and parameters: {'n_estimators': 200, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:50,188] Trial 11 finished with value: 456523.72367005056 and parameters: {'n_estimators': 200, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:51,110] Trial 12 finished with value: 466774.7711498393 and parameters: {'n_estimators': 250, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:51,967] Trial 13 finished with value: 549135.4571218443 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 7 with value: 455403.5993690506.\n",
      "[I 2025-11-27 02:16:53,005] Trial 14 finished with value: 440752.19261449407 and parameters: {'n_estimators': 300, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:54,216] Trial 15 finished with value: 544340.7975307154 and parameters: {'n_estimators': 300, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:55,463] Trial 16 finished with value: 592152.827060719 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:56,400] Trial 17 finished with value: 442698.902661947 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:57,371] Trial 18 finished with value: 551371.8776066924 and parameters: {'n_estimators': 250, 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:58,591] Trial 19 finished with value: 547103.3520258964 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 14 with value: 440752.19261449407.\n",
      "[I 2025-11-27 02:16:59,511] Trial 20 finished with value: 437814.5094586773 and parameters: {'n_estimators': 250, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 20 with value: 437814.5094586773.\n",
      "[I 2025-11-27 02:17:00,430] Trial 21 finished with value: 437932.75874696905 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 20 with value: 437814.5094586773.\n",
      "[I 2025-11-27 02:17:01,490] Trial 22 finished with value: 435275.91490496194 and parameters: {'n_estimators': 300, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:02,437] Trial 23 finished with value: 550896.7972328425 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:03,343] Trial 24 finished with value: 436084.4356395117 and parameters: {'n_estimators': 250, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:04,438] Trial 25 finished with value: 548374.7339323267 and parameters: {'n_estimators': 300, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:05,339] Trial 26 finished with value: 436654.01836443786 and parameters: {'n_estimators': 250, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:06,526] Trial 27 finished with value: 543913.6385323517 and parameters: {'n_estimators': 300, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:07,459] Trial 28 finished with value: 546979.5336719444 and parameters: {'n_estimators': 250, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 22 with value: 435275.91490496194.\n",
      "[I 2025-11-27 02:17:08,546] Trial 29 finished with value: 433668.683515436 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:09,717] Trial 30 finished with value: 552107.0444414491 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:10,796] Trial 31 finished with value: 433941.30284486734 and parameters: {'n_estimators': 300, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:11,880] Trial 32 finished with value: 433692.57461950445 and parameters: {'n_estimators': 300, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:12,979] Trial 33 finished with value: 435768.54842949385 and parameters: {'n_estimators': 300, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:14,061] Trial 34 finished with value: 433668.683515436 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:15,205] Trial 35 finished with value: 548263.7809804123 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:16,312] Trial 36 finished with value: 440117.65535581455 and parameters: {'n_estimators': 300, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:17,444] Trial 37 finished with value: 611340.8599536498 and parameters: {'n_estimators': 300, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:18,541] Trial 38 finished with value: 433668.683515436 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:18,987] Trial 39 finished with value: 628486.2317255866 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:19,636] Trial 40 finished with value: 550358.5977219286 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:20,693] Trial 41 finished with value: 433941.30284486734 and parameters: {'n_estimators': 300, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:21,799] Trial 42 finished with value: 433692.57461950445 and parameters: {'n_estimators': 300, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:22,879] Trial 43 finished with value: 435768.54842949385 and parameters: {'n_estimators': 300, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:23,966] Trial 44 finished with value: 434013.6379988035 and parameters: {'n_estimators': 300, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:25,033] Trial 45 finished with value: 435768.5484294939 and parameters: {'n_estimators': 300, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:26,162] Trial 46 finished with value: 548947.4559103992 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:27,241] Trial 47 finished with value: 441023.4377293733 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:28,099] Trial 48 finished with value: 538553.2715396908 and parameters: {'n_estimators': 200, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 29 with value: 433668.683515436.\n",
      "[I 2025-11-27 02:17:29,055] Trial 49 finished with value: 477647.40244988335 and parameters: {'n_estimators': 250, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 433668.683515436.\n",
      "\n",
      "Mejores parámetros encontrados:\n",
      "{'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "\n",
      "Validation:\n",
      "  RMSE: $433,668.68\n",
      "  MAE:  $76,838.40\n",
      "  R²:   0.4387\n",
      "\n",
      "Test:\n",
      "  RMSE: $264,510.09\n",
      "  MAE:  $69,136.89\n",
      "  R²:   0.5714\n",
      "\n",
      "✓ Random Forest completado y guardado\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 2: RANDOM FOREST CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir objetivo de Optuna\n",
    "def objective_rf(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    \n",
    "    # Crear modelo\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en validación\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Calcular RMSE (queremos minimizarlo)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Crear estudio de Optuna\n",
    "print(\"\\nBuscando hiperparámetros óptimos (50 trials)...\")\n",
    "sampler_rf = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = MedianPruner()\n",
    "\n",
    "study_rf = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=sampler_rf,\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Optimizar\n",
    "study_rf.optimize(objective_rf, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Mejores parámetros\n",
    "best_params_rf = study_rf.best_params\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(best_params_rf)\n",
    "\n",
    "# Entrenar modelo final con mejores parámetros\n",
    "rf_model_final = RandomForestRegressor(\n",
    "    **best_params_rf,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model_final.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_val_pred_rf = rf_model_final.predict(X_val)\n",
    "y_test_pred_rf = rf_model_final.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "val_rmse_rf = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
    "val_mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n",
    "val_r2_rf = r2_score(y_val, y_val_pred_rf)\n",
    "\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Registrar en MLFlow\n",
    "with mlflow.start_run(run_name=\"random_forest\"):\n",
    "    mlflow.log_param(\"model\", \"RandomForest\")\n",
    "    mlflow.log_params(best_params_rf)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse_rf)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae_rf)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2_rf)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse_rf)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae_rf)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2_rf)\n",
    "    mlflow.sklearn.log_model(rf_model_final, \"random_forest_model\")\n",
    "    joblib.dump(rf_model_final, '../models/random_forest.pkl')\n",
    "\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  RMSE: ${val_rmse_rf:,.2f}\")\n",
    "print(f\"  MAE:  ${val_mae_rf:,.2f}\")\n",
    "print(f\"  R²:   {val_r2_rf:.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  RMSE: ${test_rmse_rf:,.2f}\")\n",
    "print(f\"  MAE:  ${test_mae_rf:,.2f}\")\n",
    "print(f\"  R²:   {test_r2_rf:.4f}\")\n",
    "print(f\"\\n✓ Random Forest completado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MODELO 3: XGBOOST CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:17:32,799] A new study created in memory with name: no-name-6a324be8-6b69-4d9b-80d0-c54e7f67b76b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELO 3: XGBOOST CON OPTUNA\n",
      "======================================================================\n",
      "\n",
      "Buscando hiperparámetros óptimos (50 trials)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35f657cb6a64a66bf708ea5b48d7a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 02:18:04,919] Trial 0 finished with value: 365276.8017567039 and parameters: {'n_estimators': 150, 'max_depth': 10, 'learning_rate': 0.1205712628744377, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 365276.8017567039.\n",
      "[I 2025-11-27 02:18:20,728] Trial 1 finished with value: 375245.08609656006 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.19030368381735815, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 0 with value: 365276.8017567039.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO 3: XGBOOST CON OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir objetivo de Optuna\n",
    "def objective_xgb(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    \n",
    "    # Crear modelo\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en validación\n",
    "    y_val_pred = xgb_model.predict(X_val)\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Crear estudio de Optuna\n",
    "print(\"\\nBuscando hiperparámetros óptimos (50 trials)...\")\n",
    "sampler_xgb = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = MedianPruner()\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=sampler_xgb,\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Optimizar\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Mejores parámetros\n",
    "best_params_xgb = study_xgb.best_params\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(best_params_xgb)\n",
    "\n",
    "# Entrenar modelo final con mejores parámetros\n",
    "xgb_model_final = XGBRegressor(\n",
    "    **best_params_xgb,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model_final.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_val_pred_xgb = xgb_model_final.predict(X_val)\n",
    "y_test_pred_xgb = xgb_model_final.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "val_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_val_pred_xgb)\n",
    "val_r2_xgb = r2_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Registrar en MLFlow\n",
    "with mlflow.start_run(run_name=\"xgboost\"):\n",
    "    mlflow.log_param(\"model\", \"XGBoost\")\n",
    "    mlflow.log_params(best_params_xgb)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse_xgb)\n",
    "    mlflow.log_metric(\"val_mae\", val_mae_xgb)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2_xgb)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse_xgb)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae_xgb)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2_xgb)\n",
    "    mlflow.xgboost.log_model(xgb_model_final, \"xgboost_model\")\n",
    "    joblib.dump(xgb_model_final, '../models/xgboost.pkl')\n",
    "\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  RMSE: ${val_rmse_xgb:,.2f}\")\n",
    "print(f\"  MAE:  ${val_mae_xgb:,.2f}\")\n",
    "print(f\"  R²:   {val_r2_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  RMSE: ${test_rmse_xgb:,.2f}\")\n",
    "print(f\"  MAE:  ${test_mae_xgb:,.2f}\")\n",
    "print(f\"  R²:   {test_r2_xgb:.4f}\")\n",
    "print(f\"\\n✓ XGBoost completado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. COMPARACIÓN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Val RMSE': [val_rmse, val_rmse_rf, val_rmse_xgb],\n",
    "    'Test RMSE': [test_rmse, test_rmse_rf, test_rmse_xgb],\n",
    "    'Val MAE': [val_mae, val_mae_rf, val_mae_xgb],\n",
    "    'Test MAE': [test_mae, test_mae_rf, test_mae_xgb],\n",
    "    'Val R²': [val_r2, val_r2_rf, val_r2_xgb],\n",
    "    'Test R²': [test_r2, test_r2_rf, test_r2_xgb]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACIÓN DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Guardar tabla\n",
    "comparison_df.to_csv('../data/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Comparación guardada en ../data/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RESUMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN - FASE 3: MODELACIÓN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_model_idx = comparison_df['Test RMSE'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "best_rmse = comparison_df.loc[best_model_idx, 'Test RMSE']\n",
    "\n",
    "print(f\"\"\"\n",
    "✓ MODELOS ENTRENADOS: 3\n",
    "  1. Linear Regression (baseline)\n",
    "  2. Random Forest (ensemble con 50 trials de Optuna)\n",
    "  3. XGBoost (ensemble con 50 trials de Optuna)\n",
    "\n",
    "✓ MEJOR MODELO: {best_model_name}\n",
    "  Test RMSE: ${best_rmse:,.2f}\n",
    "\n",
    "✓ TRACKING: MLFlow\n",
    "  Ejecuta: mlflow ui\n",
    "  Dashboard: http://localhost:5000\n",
    "\n",
    "✓ MODELOS GUARDADOS:\n",
    "  linear_regression.pkl\n",
    "  random_forest.pkl\n",
    "  xgboost.pkl\n",
    "\n",
    "✓ PRÓXIMO PASO:\n",
    "  Ejecutar Notebook 04: Evaluación\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
